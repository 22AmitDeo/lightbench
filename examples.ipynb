{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (17.29s, TTFT: 0.34s, Memory: 2.35 GB, Power: 0W) \u001b[93m\t0 \u001b[0m\u001b[91mFAILED\u001b[0m\n",
      "1 (25.61s, TTFT: 1.33s, Memory: 2.56 GB, Power: 0W) \u001b[93m\t\t1 \u001b[0m\u001b[91mFAILED\u001b[0m\n",
      "1 (32.41s, TTFT: 3.17s, Memory: 3.07 GB, Power: 0W) \u001b[93m\t\t2 \u001b[0m\u001b[91mFAILED\u001b[0m\n",
      "2 (1.21s, TTFT: 0.33s, Memory: 2.33 GB, Power: 0W) \u001b[93m\t0 \u001b[0m\u001b[92mPASSED\u001b[0m\n",
      "3 (4.48s, TTFT: 0.23s, Memory: 2.33 GB, Power: 0W) \u001b[93m\t0 \u001b[0m\u001b[92mPASSED\u001b[0m\n",
      "Tests Passed: 2/3 (66.67%)\u001b[0m          \n",
      "{\n",
      "    \"passed_tests\": 2,\n",
      "    \"total_tests\": 3,\n",
      "    \"passed_percentage\": 66.67,\n",
      "    \"few_shot\": \"True\",\n",
      "    \"average_inference_time_sec\": 16.2,\n",
      "    \"average_ttft_sec\": 1.08,\n",
      "    \"quantize\": \"False\",\n",
      "    \"average_mem_usage_GB\": 2.53,\n",
      "    \"average_power_usage_W\": 0.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#                          Code Generation                         #\n",
    "####################################################################\n",
    "from lightbench.loaders.huggingface_model_loader import HFModelLoader\n",
    "from lightbench.evaluators.code_evaluator import CodeEvaluator\n",
    "   \n",
    "model_loader = HFModelLoader(\"meta-llama/Llama-3.2-1B-Instruct\", quantize=False)\n",
    "code_evaluator = CodeEvaluator(model_loader, num_test_limit=3, few_shot=True, verbose=False)\n",
    "code_evaluator.run()\n",
    "code_evaluator.print_summary()\n",
    "model_loader.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (5.25s, TTFT: 4.01s, Memory: 3.45 GB, Power: 0W) \u001b[93m\t2\u001b[0m\n",
      "2 (3.84s, TTFT: 2.49s, Memory: 2.85 GB, Power: 0W) \u001b[93m\t2\u001b[0m\n",
      "3 (3.10s, TTFT: 2.50s, Memory: 2.86 GB, Power: 0W) \u001b[93m\t10\u001b[0m\n",
      "Average score: 4.67\u001b[0m                 \n",
      "{\n",
      "    \"total_tests\": 3,\n",
      "    \"avg_score\": 4.67,\n",
      "    \"average_inference_time_sec\": 4.06,\n",
      "    \"average_ttft_sec\": 3.0,\n",
      "    \"quantize\": \"False\",\n",
      "    \"average_mem_usage_GB\": 3.05,\n",
      "    \"average_power_usage_W\": 0.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#                        Question Answering                        #\n",
    "####################################################################\n",
    "from lightbench.evaluators.text_evaluator import TextEvaluator\n",
    "from lightbench.metrics.llm_judge import LLMJudge\n",
    "from lightbench.loaders.huggingface_model_loader import HFModelLoader\n",
    "\n",
    "judge = LLMJudge()\n",
    "model_loader = HFModelLoader(\"meta-llama/Llama-3.2-1B-Instruct\", quantize=False)\n",
    "text_evaluator = TextEvaluator(model_loader, judge, num_test_limit=3, verbose=False)\n",
    "text_evaluator.run()\n",
    "text_evaluator.print_summary()\n",
    "model_loader.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
